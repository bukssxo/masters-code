{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEPJVUDmUcRX"
      },
      "outputs": [],
      "source": [
        "#relevant libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import itertools\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import scipy.stats as stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZTIi_FaDiZC"
      },
      "source": [
        "### The stocks analysed within this project is\n",
        "#### Goldman Sachs and Citibank - Investment Banks\n",
        "#### Johnson and Johnson - Pharmaceutical organisation\n",
        "#### Google and Apple - Big Technology organisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttZfNM39F67P"
      },
      "source": [
        "### Data Cleaning and Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smdBs3LTVXBl"
      },
      "outputs": [],
      "source": [
        "#testing it out - fetching historical data\n",
        "#Citibank\n",
        "citi_df = yf.download(\"C\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "citi_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BxhsgnELljA"
      },
      "outputs": [],
      "source": [
        "citi_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-TmlkD0W98t"
      },
      "outputs": [],
      "source": [
        "#Goldman Sachs\n",
        "goldman_df = yf.download(\"GS\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "goldman_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYWqKvesMwBp"
      },
      "outputs": [],
      "source": [
        "goldman_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac0IP5cNCj9C"
      },
      "outputs": [],
      "source": [
        "#Johnson and Johnson\n",
        "johnson_df = yf.download(\"JNJ\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "johnson_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg8y8j5uM0Qd"
      },
      "outputs": [],
      "source": [
        "johnson_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWl2W5c4C05-"
      },
      "outputs": [],
      "source": [
        "google_df = yf.download(\"GOOG\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "google_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyXubv_vM6M6"
      },
      "outputs": [],
      "source": [
        "google_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRO22bpXDEz7"
      },
      "outputs": [],
      "source": [
        "apple_df = yf.download(\"AAPL\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "apple_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsVnfW96M_VD"
      },
      "outputs": [],
      "source": [
        "apple_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVkEWM9CE58w"
      },
      "outputs": [],
      "source": [
        "#checking for null values for each dataframe\n",
        "\n",
        "null_citi = citi_df.isnull().sum()\n",
        "null_goldman = goldman_df.isnull().sum()\n",
        "null_johnson = johnson_df.isnull().sum()\n",
        "null_google = google_df.isnull().sum()\n",
        "null_apple = apple_df.isnull().sum()\n",
        "\n",
        "print(null_citi)\n",
        "print(null_goldman)\n",
        "print(null_johnson)\n",
        "print(null_google)\n",
        "print(null_apple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeR8AY1uFw-z"
      },
      "outputs": [],
      "source": [
        "#checking the data type for each column\n",
        "\n",
        "citi_type = citi_df.dtypes\n",
        "goldman_type = goldman_df.dtypes\n",
        "johnson_type = johnson_df.dtypes\n",
        "google_type = google_df.dtypes\n",
        "apple_type = apple_df.dtypes\n",
        "\n",
        "print(citi_type)\n",
        "print(goldman_type)\n",
        "print(johnson_type)\n",
        "print(google_type)\n",
        "print(apple_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjTgTOqTHXsR"
      },
      "source": [
        "### Initial observations\n",
        "\n",
        "##### There are no null values within any of the dataframes examined. The data types of each column is consistent through all of the dataframes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP-e8sNLICaK"
      },
      "source": [
        "#### Explanation of each column, when reviewing a stock price\n",
        "\n",
        "##### Close - the price of a stock when the markets close (the target variable)\n",
        "##### High - the price of a stock at its highest for that day\n",
        "##### Low - the price of a stock at its lowest for that day\n",
        "##### Open - the price of a stock when the markets close\n",
        "##### Volume - the number of shares traded, in relation to the stock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM8noHTJnYuv"
      },
      "source": [
        "### Functions to be used within this project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsULlUoJFrRi"
      },
      "outputs": [],
      "source": [
        "def plot_time_series (df, column_name, title, xlabel='Time Period', ylabel='Closing Price', color='red'):\n",
        "\n",
        "  \"\"\"\n",
        "  This function plots a time series from the specified dataframe.\n",
        "\n",
        "  Parameters:\n",
        "  df: The specified dataframe\n",
        "  column_name: The name of the column to plot\n",
        "  title: The title of the plot\n",
        "  xlabel: The label for the x-axis\n",
        "  ylabel: The label for the y-axis\n",
        "  color: The color of the plot line\n",
        "\n",
        "  Returns:\n",
        "  A line plot of the time series\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(title)\n",
        "  plt.plot(df.index, df[column_name], color=color)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiGjABxcqSN8"
      },
      "outputs": [],
      "source": [
        "def add_sma_column (df, column_name, window):\n",
        "  \"\"\"\n",
        "  This function creates a new dataframe based on the input dataframe and adds a Simple Moving Average (SMA) column.\n",
        "\n",
        "  Parameters:\n",
        "  df: The input dataframe\n",
        "  column_name: The name of the column to calculate the SMA on\n",
        "  window: The rolling window size for the SMA calculation\n",
        "\n",
        "  Returns:\n",
        "  A new Dataframe with the original data and the added SMA column\n",
        "  \"\"\"\n",
        "\n",
        "  new_df = df.copy()\n",
        "  new_df[f'SMA{window}'] = new_df[column_name].rolling(window).mean()\n",
        "  return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inSESH8LIKHV"
      },
      "outputs": [],
      "source": [
        "def plot_close_sma(df, close_column, sma_column, window, title, xlabel='Time Period', ylabel='Closing Price', close_color='crimson', sma_color='yellowgreen'):\n",
        "  \"\"\"\n",
        "  This function plots the closing price and the Simple Moving Average (SMA) of the specified dataframe, to compare the two.\n",
        "\n",
        "  Parameters:\n",
        "  df: The specified dataframe\n",
        "  close_column: The name of the column to plot the closing price\n",
        "  sma_column: The name of the column to plot the SMA\n",
        "  window: The rolling window size for the SMA calculation\n",
        "  title: The title of the plot\n",
        "  xlabel: The label for the x-axis\n",
        "  ylabel: The label for the y-axis\n",
        "  close_color: The color of the closing price line\n",
        "  sma_color: The color of the SMA line\n",
        "\n",
        "  Returns:\n",
        "  A line plot side by side of the closing price and the SMA\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(16, 8))\n",
        "  df[close_column].plot(label=f'{close_column}', color=close_color)\n",
        "  df[sma_column].plot(label=f'SMA{window}', color=sma_color)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLMJWryyUzfZ"
      },
      "outputs": [],
      "source": [
        "def decompose(df, column_name, period=None):\n",
        "    \"\"\"\n",
        "    This function decomposes a time series, by performing multiplicative seasonal decomposition\n",
        "    on the specified dataframe, and subsequent column.\n",
        "\n",
        "    Parameters:\n",
        "        df: The specified data frame.\n",
        "        column_name: The specified column.\n",
        "        period: The period of the time series/seasonality.\n",
        "\n",
        "    Returns:\n",
        "        The trend, seasonal and residual components of the time series as a plot for each component.\n",
        "    \"\"\"\n",
        "\n",
        "    if period is None and df.index.freq is None:\n",
        "      print(\"Warning: No period specified and index has no frequency. Setting period to 5 as a default\")\n",
        "      print(\"This plot showcases the multiplicative decompose of the specified dataframe\")\n",
        "      period = 5 #default period for daily data\n",
        "      result = seasonal_decompose(df[column_name], model='multiplicative', period=period)\n",
        "\n",
        "    elif period is not None:\n",
        "      result = seasonal_decompose(df[column_name], model='multiplicative', period=period)\n",
        "\n",
        "    else:\n",
        "      result = seasonal_decompose(df[column_name], model='multiplicative')\n",
        "\n",
        "\n",
        "    plt.rcParams.update({'figure.figsize': (20, 10)})\n",
        "    result.plot()\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD2mbEoXwjy0"
      },
      "outputs": [],
      "source": [
        "#performing the adf test - this function to be modular - used in other cells in the notebook\n",
        "\n",
        "def adf_test(df, column_name):\n",
        "  \"\"\"\n",
        "  This function performs the Adfuller test on the specified datatframe.\n",
        "\n",
        "  Parameters:\n",
        "  df: The specified data frame.\n",
        "  column_name: The specified column.\n",
        "\n",
        "  Returns:\n",
        "   Various print statements which detail the ADF statistic, P-value and critical values.\n",
        "\n",
        "  \"\"\"\n",
        "  data = df[column_name].dropna()\n",
        "  X = data.values\n",
        "  results = adfuller(X)\n",
        "  print('ADF Statistic: %f' % results[0])\n",
        "  print('P-value: %f' % results[1])\n",
        "  print('Critical Values:')\n",
        "  for key, value in results[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbdSvfeE6Hyd"
      },
      "outputs": [],
      "source": [
        "def plot_acf_pacf(df, column_name, lags=40, title_suffix=\"\"):\n",
        "  \"\"\"\n",
        "  This function plots the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF)\n",
        "  for the 'Close column in the specified dataframe.\n",
        "\n",
        "  Parameters:\n",
        "  df: The dataframe containing the time series data.\n",
        "  column_name: The name of the column to plot ACF and PACF for.\n",
        "  lags: The number of lags to display in the plots - set at lags = 40 to make plot readable.\n",
        "  title_suffix: A string to append to the plot titles (e.g., stock ticker).\n",
        "\n",
        "  Returns:\n",
        "  Displays ACF and PACF plots.\n",
        "  \"\"\"\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "  plot_acf(df[column_name].dropna(), lags=lags, ax=axes[0])\n",
        "  axes[0].set_title(f'Autocorrelation Function (ACF) - {column_name}{title_suffix}')\n",
        "  plot_pacf(df[column_name].dropna(), lags=lags, ax=axes[1])\n",
        "  axes[1].set_title(f'Partial Autocorrelation Function (PACF) - {column_name}{title_suffix}')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcpERAw2hM-a"
      },
      "outputs": [],
      "source": [
        "def calculate_and_plot_log_returns(df, column_name, title_suffix=\"\"):\n",
        "  \"\"\"\n",
        "  This function calculates the log returns for the 'Close' column within the specified dataframe,\n",
        "  plots the log returns over time, and displays a histogram and Q-Q plot\n",
        "  to visualise the distribution of the log returns.\n",
        "\n",
        "  Parameters:\n",
        "  df: The dataframe containing the time series data.\n",
        "  column_name: The name of the column to calculate log returns for (usually 'Close').\n",
        "  title_suffix: A string to append to the plot titles - stock name.\n",
        "\n",
        "  Returns:\n",
        "  Displays a plot of log returns, a histogram, and a Q-Q plot.\n",
        "  \"\"\"\n",
        "\n",
        "  #calculates the log returns\n",
        "  log_returns = np.log(df[column_name] / df[column_name].shift(1)).dropna()\n",
        "\n",
        "  #plots log returns over time\n",
        "  plt.figure(figsize=(16, 6))\n",
        "  log_returns.plot()\n",
        "  plt.title(f'Log Returns - {column_name}{title_suffix}')\n",
        "  plt.xlabel('Time Period')\n",
        "  plt.ylabel('Log Return')\n",
        "  plt.show()\n",
        "\n",
        "  #plots histogram of log returns\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.histplot(log_returns, kde=True, bins=50)\n",
        "  plt.title(f'Distribution of Log Returns - {column_name}{title_suffix}')\n",
        "  plt.xlabel('Log Return')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzDR5LT3zNg7"
      },
      "outputs": [],
      "source": [
        "def first_order_diff(df, price_type, ticker):\n",
        "  \"\"\"\n",
        "  This function performs a first-order differencing on the specified dataframe.\n",
        "\n",
        "  Parameters:\n",
        "  df: The specified dataframe\n",
        "  column_name: The name of the column to perform first-order differencing on\n",
        "\n",
        "  Returns:\n",
        "  A new dataframe with the first-order differenced column\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "  col = (price_type, ticker)\n",
        "  diff_col_name = f\"{price_type}_{ticker}_diff\"\n",
        "  df[diff_col_name] = df[col].diff()\n",
        "  display(df[[col]].join(df[[diff_col_name]]).tail())\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUQpQIINKhOU"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqPfFnkAWbXM"
      },
      "outputs": [],
      "source": [
        "stocks = {\n",
        "    \"AAPL\": apple_df,\n",
        "    \"GOOG\": google_df,\n",
        "    \"GS\": goldman_df,\n",
        "    \"JNJ\": johnson_df,\n",
        "    \"C\": citi_df\n",
        "}\n",
        "\n",
        "#computing the log returns and concatenate into a single df\n",
        "returns_list = []\n",
        "for ticker, df in stocks.items():\n",
        "    df = df.copy()\n",
        "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
        "    df = df[['Log_Returns']].dropna()\n",
        "    df.rename(columns={'Log_Returns': ticker}, inplace=True)\n",
        "    returns_list.append(df)\n",
        "\n",
        "returns_df = pd.concat(returns_list, axis=1)\n",
        "\n",
        "#plots\n",
        "plt.figure(figsize=(10, 6))\n",
        "returns_df.boxplot()\n",
        "plt.title(\"Boxplot of Daily Log Returns for All Stocks\")\n",
        "plt.ylabel(\"Log Returns\")\n",
        "plt.grid(True, alpha=0.4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1h41qOef_D4"
      },
      "outputs": [],
      "source": [
        "outlier_counts = {}\n",
        "\n",
        "for ticker in returns_df.columns:\n",
        "    series = returns_df[ticker].dropna()\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = series[(series < lower) | (series > upper)]\n",
        "    outlier_counts[ticker] = len(outliers)\n",
        "\n",
        "print(outlier_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NVP2Zxz2PFx"
      },
      "source": [
        "### Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy7PkL19b5vU"
      },
      "outputs": [],
      "source": [
        "plot_time_series(apple_df, 'Close', 'Apple Stock Price', color='blueviolet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8lk8zi8rhEm"
      },
      "outputs": [],
      "source": [
        "apple_sma = add_sma_column(apple_df, 'Close', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofTTWIn8rsNM"
      },
      "outputs": [],
      "source": [
        "apple_sma.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "351YyjhIrukh"
      },
      "outputs": [],
      "source": [
        "plot_close_sma(apple_sma, 'Close', 'SMA30', 30, 'Apple Stock Price with 30 Day SMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uazEYAN0r3lj"
      },
      "outputs": [],
      "source": [
        "result = decompose(apple_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr4PGP1Or8to"
      },
      "outputs": [],
      "source": [
        "results = adf_test(apple_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTUWBuo-sE_J"
      },
      "outputs": [],
      "source": [
        "plot_acf_pacf(apple_df, 'Close', title_suffix=' - Apple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwqO52EPsZhO"
      },
      "outputs": [],
      "source": [
        "calculate_and_plot_log_returns(apple_df, 'Close', title_suffix=' - Apple')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6zg9jbvqhai"
      },
      "source": [
        "### Citi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XYd0_zUHgy1"
      },
      "outputs": [],
      "source": [
        "plot_time_series(citi_df, 'Close', 'Citi Stock Price', color='lightcoral')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM3NFvkU_Wf-"
      },
      "outputs": [],
      "source": [
        "citi_sma = add_sma_column(citi_df, 'Close', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzAUoUyJ_kfT"
      },
      "outputs": [],
      "source": [
        "citi_sma.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG_s2UJEZTS3"
      },
      "outputs": [],
      "source": [
        "plot_close_sma(citi_sma, 'Close', 'SMA30', 30, 'Citi Stock Price with 30 Day SMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXB6GvziNqQe"
      },
      "outputs": [],
      "source": [
        "result = decompose(citi_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7MZDoOU6dcZ"
      },
      "outputs": [],
      "source": [
        "results = adf_test(citi_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8YfF0fRguMg"
      },
      "outputs": [],
      "source": [
        "plot_acf_pacf(citi_df, 'Close', title_suffix=' - Citi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSJ1si-Ti6DF"
      },
      "outputs": [],
      "source": [
        "calculate_and_plot_log_returns(citi_df, 'Close', title_suffix=' - Citi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LU3b01w2Mc-"
      },
      "source": [
        "### Goldman Sachs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01hiCMb0QC-Z"
      },
      "outputs": [],
      "source": [
        "plot_time_series(goldman_df, 'Close', 'Goldman Sachs Stock Price', color='goldenrod')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RWGN57lqc4Q"
      },
      "outputs": [],
      "source": [
        "goldman_sma = add_sma_column(goldman_df, 'Close', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XlLIkPVqmph"
      },
      "outputs": [],
      "source": [
        "goldman_sma.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLt2Fq5yqo2z"
      },
      "outputs": [],
      "source": [
        "plot_close_sma(goldman_sma, 'Close', 'SMA30', 30, 'Goldman Sachs Stock Price with 30 Day SMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpcgIXPOq5Dj"
      },
      "outputs": [],
      "source": [
        "result = decompose(goldman_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orOoxm0Bq7aI"
      },
      "outputs": [],
      "source": [
        "results = adf_test(goldman_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VglDZGc7q-oB"
      },
      "outputs": [],
      "source": [
        "plot_acf_pacf(goldman_df, 'Close', title_suffix=' - GS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYhyU5oxrE1d"
      },
      "outputs": [],
      "source": [
        "calculate_and_plot_log_returns(goldman_df, 'Close', title_suffix=' - GS')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nej3SghQPBtP"
      },
      "source": [
        "### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZguVoZfgO9ME"
      },
      "outputs": [],
      "source": [
        "plot_time_series(google_df, 'Close', 'Google Stock Price', color='cornflowerblue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrmcVSQDob9j"
      },
      "outputs": [],
      "source": [
        "google_sma = add_sma_column(google_df, 'Close', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5txEGz0zoiIR"
      },
      "outputs": [],
      "source": [
        "google_sma.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR3Cncrloll0"
      },
      "outputs": [],
      "source": [
        "plot_close_sma(google_sma, 'Close', 'SMA30', 30, 'Google Stock Price with 30 Day SMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvR5zFvxoxMY"
      },
      "outputs": [],
      "source": [
        "result = decompose(google_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO3WEtX0o6Ll"
      },
      "outputs": [],
      "source": [
        "results = adf_test(google_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydNs4fRto91M"
      },
      "outputs": [],
      "source": [
        "plot_acf_pacf(google_df, 'Close', title_suffix=' - Google')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDVnOfT6pCwH"
      },
      "outputs": [],
      "source": [
        "calculate_and_plot_log_returns(google_df, 'Close', title_suffix=' - Google')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXVLREZI2IcZ"
      },
      "source": [
        "### Johnson and Johnson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAYMY8S3PZ3j"
      },
      "outputs": [],
      "source": [
        "plot_time_series(johnson_df, 'Close', 'JNJ Stock Price', color='mediumseagreen')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXGDvv6pgir"
      },
      "outputs": [],
      "source": [
        "johnson_sma = add_sma_column(johnson_df, 'Close', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FygW6AQ0pqvy"
      },
      "outputs": [],
      "source": [
        "johnson_sma.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qIzEBMApuxn"
      },
      "outputs": [],
      "source": [
        "plot_close_sma(johnson_sma, 'Close', 'SMA30', 30, 'JNJ Stock Price with 30 Day SMA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v78O5lxrp0SB"
      },
      "outputs": [],
      "source": [
        "result = decompose(johnson_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4rPrdTEp8fO"
      },
      "outputs": [],
      "source": [
        "results = adf_test(johnson_df, 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAyaV69UqCDL"
      },
      "outputs": [],
      "source": [
        "plot_acf_pacf(johnson_df, 'Close', title_suffix=' - JNJ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TK--VQfqKWn"
      },
      "outputs": [],
      "source": [
        "calculate_and_plot_log_returns(johnson_df, 'Close', title_suffix=' - JNJ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpZReIrxmj10"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ihjJWqmpoZ"
      },
      "source": [
        "### Traditional Time Series Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldETUg-WnVh9"
      },
      "source": [
        "#### ARIMA (Auto-regressive moving average)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfAn3b24stXk"
      },
      "source": [
        "###### Notes: All stocks in this project are non-stationary, due to the nature of the time series - trends upwards and downwards so differencing is performed on all the stocks - update after differencing - all time series are now stationary, ready for model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXmAmDP9mlMD"
      },
      "source": [
        "##### Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NegdHY927Ws2"
      },
      "outputs": [],
      "source": [
        "#apple\n",
        "apple_df_new = first_order_diff(apple_df, 'Close', 'AAPL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GToTWulQ7bBH"
      },
      "outputs": [],
      "source": [
        "#reviewing effects\n",
        "results = adf_test(apple_df_new, 'Close_AAPL_diff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX-BNNwb8TYE"
      },
      "outputs": [],
      "source": [
        "apple_df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FoJkgA4mYCt"
      },
      "outputs": [],
      "source": [
        "close_prices = apple_df_new['Close']\n",
        "\n",
        "#define the p, d, q ranges\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = ARIMA(close_prices, order=order)\n",
        "        results = model.fit()\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIW8ycemxfjo"
      },
      "outputs": [],
      "source": [
        "#define train and test set in the time series, then build the ARIMA model, alongside its summary\n",
        "\n",
        "train = apple_df_new['Close'][:-30]\n",
        "test = apple_df_new['Close'][-30:]\n",
        "\n",
        "apple_model = ARIMA(train, order=(0, 1, 0))\n",
        "apple_model_fit = apple_model.fit()\n",
        "print(apple_model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qWwo-f4yIdQ"
      },
      "outputs": [],
      "source": [
        "#forecasting values up to 30 steps, and calculating error metrics\n",
        "\n",
        "forecast = apple_model_fit.forecast(steps=30)\n",
        "print(forecast)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "mae = mean_absolute_error(test, forecast)\n",
        "mape = mean_absolute_percentage_error(test, forecast)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN1aJp9eyOS8"
      },
      "outputs": [],
      "source": [
        "#plot actual vs forecast values - apple\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test.index, test, label='Actual', color='black')\n",
        "plt.plot(test.index, forecast, label='Forecast', color='red')\n",
        "plt.title(\"ARIMA Forecast vs Actual - Apple\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd_Pvxt5mBtT"
      },
      "source": [
        "##### Citi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN3SRlaU68GA"
      },
      "outputs": [],
      "source": [
        "#citi\n",
        "citi_df_new = first_order_diff(citi_df, 'Close', 'C')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv4gpm6X7CdT"
      },
      "outputs": [],
      "source": [
        "#reviewing effects\n",
        "results = adf_test(citi_df_new, 'Close_C_diff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c33ncWhQmR1Q"
      },
      "outputs": [],
      "source": [
        "close_prices = citi_df_new['Close']\n",
        "\n",
        "#define the p, d, q ranges\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = ARIMA(close_prices, order=order)\n",
        "        results = model.fit()\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8IVivqqsCgC"
      },
      "outputs": [],
      "source": [
        "#define train and test set in the time series, then build the ARIMA model, alongside its summary\n",
        "\n",
        "train = citi_df_new['Close'][:-30]\n",
        "test = citi_df_new['Close'][-30:]\n",
        "\n",
        "citi_model = ARIMA(train, order=(0, 1, 2))\n",
        "citi_model_fit = citi_model.fit()\n",
        "print(citi_model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH8ZKft3vweB"
      },
      "outputs": [],
      "source": [
        "#forecasting values up to 30 steps, and calculating error metrics\n",
        "\n",
        "forecast = citi_model_fit.forecast(steps=30)\n",
        "print(forecast)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "mae = mean_absolute_error(test, forecast)\n",
        "mape = mean_absolute_percentage_error(test, forecast)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsYotZPgv3Ad"
      },
      "outputs": [],
      "source": [
        "#plot actual vs forecast values - citi\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test.index, test, label='Actual', color='black')\n",
        "plt.plot(test.index, forecast, label='Forecast', color='lightcoral')\n",
        "plt.title(\"ARIMA Forecast vs Actual - Citi\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guD5XvfMko9L"
      },
      "source": [
        "##### Goldman Sachs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iE8UVYcxRk4"
      },
      "outputs": [],
      "source": [
        "#goldman sachs\n",
        "goldman_df_new = first_order_diff(goldman_df, 'Close', 'GS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzaTH98b3Z7v"
      },
      "outputs": [],
      "source": [
        "#reviewing effects\n",
        "results = adf_test(goldman_df_new, 'Close_GS_diff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCd9F4iVjvg-"
      },
      "outputs": [],
      "source": [
        "close_prices = goldman_df_new['Close']\n",
        "\n",
        "#function which chooses the best ARIMA order for time series\n",
        "\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = ARIMA(close_prices, order=order)\n",
        "        results = model.fit()\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu2TqtT3ComC"
      },
      "outputs": [],
      "source": [
        "#define train and test set\n",
        "train = goldman_df_new['Close'][:-30]\n",
        "test = goldman_df_new['Close'][-30:]\n",
        "\n",
        "#build model\n",
        "goldman_model = ARIMA(train, order=(1, 1, 2))\n",
        "goldman_model_fit = goldman_model.fit()\n",
        "print(goldman_model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb4Ga1V1CMmu"
      },
      "outputs": [],
      "source": [
        "# Forecasting the next 30 steps\n",
        "forecast = goldman_model_fit.forecast(steps=30)\n",
        "print(forecast)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "mae = mean_absolute_error(test, forecast)\n",
        "mape = mean_absolute_percentage_error(test, forecast)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyPzlP0VaRkI"
      },
      "outputs": [],
      "source": [
        "#plot actual vs forecast values - goldman sachs\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test.index, test, label='Actual', color='black')\n",
        "plt.plot(test.index, forecast, label='Forecast', color='goldenrod')\n",
        "plt.title(\"ARIMA Forecast vs Actual - Goldman Sachs\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAwlCtfEl6XA"
      },
      "source": [
        "##### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sglUoAm30C95"
      },
      "outputs": [],
      "source": [
        "#google\n",
        "google_df_new = first_order_diff(google_df, 'Close', 'GOOG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm87P5Cj6wKM"
      },
      "outputs": [],
      "source": [
        "#reviewing effects\n",
        "results = adf_test(google_df_new, 'Close_GOOG_diff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ARlAyKOmMr-"
      },
      "outputs": [],
      "source": [
        "close_prices = google_df_new['Close']\n",
        "\n",
        "#function which chooses the best ARIMA order for time series\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = ARIMA(close_prices, order=order)\n",
        "        results = model.fit()\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErY38-pJnXFv"
      },
      "outputs": [],
      "source": [
        "#define train and test set in the time series, then build the ARIMA model, alongside its summary\n",
        "\n",
        "train = google_df_new['Close'][:-30]\n",
        "test = google_df_new['Close'][-30:]\n",
        "\n",
        "google_model = ARIMA(train, order=(2, 1, 2))\n",
        "google_model_fit = google_model.fit()\n",
        "print(google_model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRUXx6j9oRaI"
      },
      "outputs": [],
      "source": [
        "#forecasting values up to 30 steps, and calculating error metrics\n",
        "\n",
        "forecast = google_model_fit.forecast(steps=30)\n",
        "print(forecast)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "mae = mean_absolute_error(test, forecast)\n",
        "mape = mean_absolute_percentage_error(test, forecast)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VAV_HQuo7x-"
      },
      "outputs": [],
      "source": [
        "#plot actual vs forecast values - google\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test.index, test, label='Actual', color='black')\n",
        "plt.plot(test.index, forecast, label='Forecast', color='cornflowerblue')\n",
        "plt.title(\"ARIMA Forecast vs Actual - Google\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qASOvpesmg65"
      },
      "source": [
        "##### Johnson and Johnson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJGH8vfZ7HM8"
      },
      "outputs": [],
      "source": [
        "#johnson-johnson\n",
        "jnj_df_new = first_order_diff(johnson_df, 'Close', 'JNJ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBp-V-oh7TSr"
      },
      "outputs": [],
      "source": [
        "#reviewing effects\n",
        "results = adf_test(jnj_df_new, 'Close_JNJ_diff')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7IDmqFcmVnc"
      },
      "outputs": [],
      "source": [
        "close_prices = jnj_df_new['Close']\n",
        "\n",
        "#function which chooses the best ARIMA order for time series\n",
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = ARIMA(close_prices, order=order)\n",
        "        results = model.fit()\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kuaFLb1wCr2"
      },
      "outputs": [],
      "source": [
        "#define train and test set in the time series, then build the ARIMA model, alongside its summary\n",
        "\n",
        "train = jnj_df_new['Close'][:-30]\n",
        "test = jnj_df_new['Close'][-30:]\n",
        "\n",
        "jnj_model = ARIMA(train, order=(2, 1, 2))\n",
        "jnj_model_fit = jnj_model.fit()\n",
        "print(jnj_model_fit.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWD7k4lvxFOC"
      },
      "outputs": [],
      "source": [
        "#forecasting values up to 30 steps, and calculating error metrics\n",
        "\n",
        "forecast = jnj_model_fit.forecast(steps=30)\n",
        "print(forecast)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast))\n",
        "mae = mean_absolute_error(test, forecast)\n",
        "mape = mean_absolute_percentage_error(test, forecast)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUaMsiexxNXE"
      },
      "outputs": [],
      "source": [
        "#plot actual vs forecast values - johnson and johnson\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test.index, test, label='Actual', color='black')\n",
        "plt.plot(test.index, forecast, label='Forecast', color='mediumseagreen')\n",
        "plt.title(\"ARIMA Forecast vs Actual - Johnson and Johnson\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEaYwaQ_zg_0"
      },
      "source": [
        "#### SARIMAX (Seasonal Autoregressive Integrated Moving Average with Exogenous Regressors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBHhtQVIyUV3"
      },
      "source": [
        "##### Goldman Sachs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6eo104Rq6ET"
      },
      "outputs": [],
      "source": [
        "#downloading sp 500 to use as an exogenous variable\n",
        "\n",
        "sp_500 = yf.download('^GSPC', start='2015-01-01', end='2025-01-01')\n",
        "sp_500.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe4TjUzNwBgj"
      },
      "outputs": [],
      "source": [
        "gs_sarima = pd.concat([goldman_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "gs_sarima.columns = [\"GS_Close\", \"SP500_Close\"]\n",
        "gs_sarima = gs_sarima.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPqiYUfot00b"
      },
      "outputs": [],
      "source": [
        "gs_sarima.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56xgh-sVuktB"
      },
      "outputs": [],
      "source": [
        "#performing stationary, differencing\n",
        "\n",
        "gs_sarima[\"GS_Returns\"] = np.log(gs_sarima[\"GS_Close\"] / gs_sarima[\"GS_Close\"].shift(1))\n",
        "gs_sarima[\"SP500_Returns\"] = np.log(gs_sarima[\"SP500_Close\"] / gs_sarima[\"SP500_Close\"].shift(1))\n",
        "gs_sarima = gs_sarima.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SV7Vzu5zAXi"
      },
      "outputs": [],
      "source": [
        "#defining X and y data\n",
        "\n",
        "y = gs_sarima[\"GS_Returns\"].reset_index(drop=True)\n",
        "X = gs_sarima[[\"SP500_Returns\"]].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TY48PrFznm4"
      },
      "outputs": [],
      "source": [
        "#train and test split\n",
        "\n",
        "train_size = int(len(y) * 0.8)\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjBDlA9Q3GNM"
      },
      "outputs": [],
      "source": [
        "p = q = range(0, 3)\n",
        "d = [0]  # returns are already stationary\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            y_train,\n",
        "            order=order,\n",
        "            seasonal_order=(0, 0, 0, 0),  # no seasonality for stock returns\n",
        "            exog=X_train,\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        results = model.fit(disp=False)\n",
        "\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "print(f\"Best SARIMAX order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfC3kQHw-MGI"
      },
      "outputs": [],
      "source": [
        "#to forecast returns\n",
        "forecast = best_model.get_forecast(steps=len(y_test), exog=X_test)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "\n",
        "#metrics on returns\n",
        "rmse_ret = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
        "mae_ret = mean_absolute_error(y_test, forecast_mean)\n",
        "\n",
        "print(\"Metrics on Returns\")\n",
        "print(f\"RMSE: {rmse_ret:.6f}, MAE: {mae_ret:.6f}\")\n",
        "\n",
        "#to reconstruct prices\n",
        "goldman_prices = gs_sarima[\"GS_Close\"].reset_index(drop=True)\n",
        "\n",
        "# actual test prices\n",
        "actual_prices = goldman_prices[train_size:]\n",
        "\n",
        "# forecasted returns -> cumulative sum -> exponentiate -> multiply by last train price\n",
        "last_train_price = goldman_prices[train_size - 1]\n",
        "forecast_prices = last_train_price * np.exp(forecast_mean.cumsum())\n",
        "\n",
        "# Metrics on prices\n",
        "rmse_price = np.sqrt(mean_squared_error(actual_prices, forecast_prices))\n",
        "mae_price = mean_absolute_error(actual_prices, forecast_prices)\n",
        "mape_price = mean_absolute_percentage_error(actual_prices, forecast_prices)\n",
        "\n",
        "print(\"Metrics on Prices\")\n",
        "print(f\"RMSE: {rmse_price:.2f}, MAE: {mae_price:.2f}, MAPE: {mape_price:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58CAkZoXwQ-Z"
      },
      "source": [
        "##### Citi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C87v7kswVZ9"
      },
      "outputs": [],
      "source": [
        "citi_sarima = pd.concat([citi_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "citi_sarima.columns = [\"Citi_Close\", \"SP500_Close\"]\n",
        "citi_sarima = citi_sarima.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kft-kn7hO86"
      },
      "outputs": [],
      "source": [
        "citi_sarima.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u_-JbDzjh6b"
      },
      "outputs": [],
      "source": [
        "#performing stationary, differencing\n",
        "\n",
        "citi_sarima[\"Citi_Returns\"] = np.log(citi_sarima[\"Citi_Close\"] / citi_sarima[\"Citi_Close\"].shift(1))\n",
        "citi_sarima[\"SP500_Returns\"] = np.log(citi_sarima[\"SP500_Close\"] / citi_sarima[\"SP500_Close\"].shift(1))\n",
        "citi_sarima = citi_sarima.dropna()\n",
        "\n",
        "#defining X and y data\n",
        "\n",
        "y = citi_sarima[\"Citi_Returns\"].reset_index(drop=True)\n",
        "X = citi_sarima[[\"SP500_Returns\"]].reset_index(drop=True)\n",
        "\n",
        "\n",
        "#train and test split\n",
        "\n",
        "train_size = int(len(y) * 0.8)\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FomfKeMnm4Z0"
      },
      "outputs": [],
      "source": [
        "p = q = range(0, 3)\n",
        "d = [0]  # returns are already stationary\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            y_train,\n",
        "            order=order,\n",
        "            seasonal_order=(0, 0, 0, 0),  # no seasonality for stock returns\n",
        "            exog=X_train,\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        results = model.fit(disp=False)\n",
        "\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "print(f\"Best SARIMAX order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbTMZYiunotY"
      },
      "outputs": [],
      "source": [
        "#forecast returns\n",
        "forecast = best_model.get_forecast(steps=len(y_test), exog=X_test)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "\n",
        "#metrics on returns\n",
        "rmse_ret = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
        "mae_ret = mean_absolute_error(y_test, forecast_mean)\n",
        "\n",
        "print(\"Metrics on Returns\")\n",
        "print(f\"RMSE: {rmse_ret:.6f}, MAE: {mae_ret:.6f}\")\n",
        "\n",
        "\n",
        "#reconstruct prices\n",
        "citi_prices = citi_sarima[\"Citi_Close\"].reset_index(drop=True)\n",
        "\n",
        "# actual test prices\n",
        "actual_prices = citi_prices[train_size:]\n",
        "\n",
        "# forecasted returns -> cumulative sum -> exponentiate -> multiply by last train price\n",
        "last_train_price = citi_prices[train_size - 1]\n",
        "forecast_prices = last_train_price * np.exp(forecast_mean.cumsum())\n",
        "\n",
        "#metrics on prices\n",
        "rmse_price = np.sqrt(mean_squared_error(actual_prices, forecast_prices))\n",
        "mae_price = mean_absolute_error(actual_prices, forecast_prices)\n",
        "mape_price = mean_absolute_percentage_error(actual_prices, forecast_prices)\n",
        "\n",
        "print(\"Metrics on Prices\")\n",
        "print(f\"RMSE: {rmse_price:.2f}, MAE: {mae_price:.2f}, MAPE: {mape_price:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oryWy01CoHI_"
      },
      "source": [
        "##### Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3--dNGSUoTgU"
      },
      "outputs": [],
      "source": [
        "apple_sarima = pd.concat([apple_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "apple_sarima.columns = [\"Apple_Close\", \"SP500_Close\"]\n",
        "apple_sarima = apple_sarima.dropna()\n",
        "\n",
        "apple_sarima.head()\n",
        "\n",
        "\n",
        "#performing stationary, differencing\n",
        "\n",
        "apple_sarima[\"Apple_Returns\"] = np.log(apple_sarima[\"Apple_Close\"] / apple_sarima[\"Apple_Close\"].shift(1))\n",
        "apple_sarima[\"SP500_Returns\"] = np.log(apple_sarima[\"SP500_Close\"] / apple_sarima[\"SP500_Close\"].shift(1))\n",
        "apple_sarima = apple_sarima.dropna()\n",
        "\n",
        "#defining X and y data\n",
        "\n",
        "y = apple_sarima[\"Apple_Returns\"].reset_index(drop=True)\n",
        "X = apple_sarima[[\"SP500_Returns\"]].reset_index(drop=True)\n",
        "\n",
        "#train and test split\n",
        "\n",
        "train_size = int(len(y) * 0.8)\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBc3p9QnpVip"
      },
      "outputs": [],
      "source": [
        "p = q = range(0, 3)\n",
        "d = [0]  # returns are already stationary\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            y_train,\n",
        "            order=order,\n",
        "            seasonal_order=(0, 0, 0, 0),  # no seasonality for stock returns\n",
        "            exog=X_train,\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        results = model.fit(disp=False)\n",
        "\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "print(f\"Best SARIMAX order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObGcHaaxm-mW"
      },
      "outputs": [],
      "source": [
        "#forecast returns\n",
        "forecast = best_model.get_forecast(steps=len(y_test), exog=X_test)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "\n",
        "#metrics on returns\n",
        "rmse_ret = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
        "mae_ret = mean_absolute_error(y_test, forecast_mean)\n",
        "\n",
        "print(\"Metrics on Returns\")\n",
        "print(f\"RMSE: {rmse_ret:.6f}, MAE: {mae_ret:.6f}\")\n",
        "\n",
        "#reconstruct prices\n",
        "apple_prices = apple_sarima[\"Apple_Close\"].reset_index(drop=True)\n",
        "\n",
        "# actual test prices\n",
        "actual_prices = apple_prices[train_size:]\n",
        "\n",
        "# forecasted returns -> cumulative sum -> exponentiate -> multiply by last train price\n",
        "last_train_price = apple_prices[train_size - 1]\n",
        "forecast_prices = last_train_price * np.exp(forecast_mean.cumsum())\n",
        "\n",
        "#metrics on prices\n",
        "rmse_price = np.sqrt(mean_squared_error(actual_prices, forecast_prices))\n",
        "mae_price = mean_absolute_error(actual_prices, forecast_prices)\n",
        "mape_price = mean_absolute_percentage_error(actual_prices, forecast_prices)\n",
        "\n",
        "print(\"Metrics on Prices\")\n",
        "print(f\"RMSE: {rmse_price:.2f}, MAE: {mae_price:.2f}, MAPE: {mape_price:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI5Y0h0LA_V6"
      },
      "outputs": [],
      "source": [
        "#last known actual price before test period\n",
        "last_price = apple_sarima[\"Apple_Close\"].iloc[train_size]\n",
        "\n",
        "#forecasted returns\n",
        "forecast_returns = forecast_mean.values\n",
        "\n",
        "#convert returns to prices\n",
        "forecast_prices = [last_price]\n",
        "for r in forecast_returns:\n",
        "    next_price = forecast_prices[-1] * np.exp(r)\n",
        "    forecast_prices.append(next_price)\n",
        "\n",
        "#drop the initial last_price (keep only forecasted steps)\n",
        "forecast_prices = forecast_prices[1:]\n",
        "\n",
        "#actual test prices\n",
        "actual_prices = apple_sarima[\"Apple_Close\"].iloc[train_size:].values\n",
        "\n",
        "#plot\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(actual_prices, label=\"Actual Price\", color=\"black\")\n",
        "plt.plot(forecast_prices, label=\"SARIMAX Forecast (Price)\", color=\"red\", linestyle=\"--\")\n",
        "plt.title(\"SARIMAX Forecast vs Actual (AAPL Closing Price)\")\n",
        "plt.xlabel(\"Time Index (Test Period)\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlFlQsFMrj35"
      },
      "source": [
        "##### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mb0dY6gsgP-"
      },
      "outputs": [],
      "source": [
        "google_sarima = pd.concat([google_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "google_sarima.columns = [\"Google_Close\", \"SP500_Close\"]\n",
        "google_sarima = google_sarima.dropna()\n",
        "\n",
        "google_sarima.head()\n",
        "\n",
        "\n",
        "#performing stationary, differencing\n",
        "\n",
        "google_sarima[\"Google_Returns\"] = np.log(google_sarima[\"Google_Close\"] / google_sarima[\"Google_Close\"].shift(1))\n",
        "google_sarima[\"SP500_Returns\"] = np.log(google_sarima[\"SP500_Close\"] / google_sarima[\"SP500_Close\"].shift(1))\n",
        "google_sarima = google_sarima.dropna()\n",
        "\n",
        "#defining X and y data\n",
        "\n",
        "y = google_sarima[\"Google_Returns\"].reset_index(drop=True)\n",
        "X = google_sarima[[\"SP500_Returns\"]].reset_index(drop=True)\n",
        "\n",
        "#train and test split\n",
        "\n",
        "train_size = int(len(y) * 0.8)\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IgBVHLfwWtD"
      },
      "outputs": [],
      "source": [
        "p = q = range(0, 3)\n",
        "d = [0]  # returns are already stationary\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            y_train,\n",
        "            order=order,\n",
        "            seasonal_order=(0, 0, 0, 0),  # no seasonality for stock returns\n",
        "            exog=X_train,\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        results = model.fit(disp=False)\n",
        "\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "print(f\"Best SARIMAX order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZjgKYxVw9vc"
      },
      "outputs": [],
      "source": [
        "#forecast returns\n",
        "forecast = best_model.get_forecast(steps=len(y_test), exog=X_test)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "\n",
        "#metrics on returns\n",
        "rmse_ret = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
        "mae_ret = mean_absolute_error(y_test, forecast_mean)\n",
        "\n",
        "print(\"Metrics on Returns\")\n",
        "print(f\"RMSE: {rmse_ret:.6f}, MAE: {mae_ret:.6f}\")\n",
        "\n",
        "#reconstruct prices\n",
        "google_prices = google_sarima[\"Google_Close\"].reset_index(drop=True)\n",
        "\n",
        "# actual test prices\n",
        "actual_prices = google_prices[train_size:]\n",
        "\n",
        "# forecasted returns -> cumulative sum -> exponentiate -> multiply by last train price\n",
        "last_train_price = google_prices[train_size - 1]\n",
        "forecast_prices = last_train_price * np.exp(forecast_mean.cumsum())\n",
        "\n",
        "#metrics on prices\n",
        "rmse_price = np.sqrt(mean_squared_error(actual_prices, forecast_prices))\n",
        "mae_price = mean_absolute_error(actual_prices, forecast_prices)\n",
        "mape_price = mean_absolute_percentage_error(actual_prices, forecast_prices)\n",
        "\n",
        "print(\"Metrics on Prices\")\n",
        "print(f\"RMSE: {rmse_price:.2f}, MAE: {mae_price:.2f}, MAPE: {mape_price:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqBRwyByxFPO"
      },
      "source": [
        "##### Johnson and Johnson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btV8w1k4xeYU"
      },
      "outputs": [],
      "source": [
        "jnj_sarima = pd.concat([johnson_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "jnj_sarima.columns = [\"Johnson_Close\", \"SP500_Close\"]\n",
        "jnj_sarima = jnj_sarima.dropna()\n",
        "\n",
        "jnj_sarima.head()\n",
        "\n",
        "\n",
        "#performing stationary, differencing\n",
        "\n",
        "jnj_sarima[\"Johnson_Returns\"] = np.log(jnj_sarima[\"Johnson_Close\"] / jnj_sarima[\"Johnson_Close\"].shift(1))\n",
        "jnj_sarima[\"SP500_Returns\"] = np.log(jnj_sarima[\"SP500_Close\"] / jnj_sarima[\"SP500_Close\"].shift(1))\n",
        "jnj_sarima = jnj_sarima.dropna()\n",
        "\n",
        "#defining X and y data\n",
        "\n",
        "y = jnj_sarima[\"Johnson_Returns\"].reset_index(drop=True)\n",
        "X = jnj_sarima[[\"SP500_Returns\"]].reset_index(drop=True)\n",
        "\n",
        "#train and test split\n",
        "\n",
        "train_size = int(len(y) * 0.8)\n",
        "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZodsLs_7Rgy"
      },
      "outputs": [],
      "source": [
        "p = q = range(0, 3)\n",
        "d = [0]  # returns are already stationary\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "best_aic = np.inf\n",
        "best_order = None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            y_train,\n",
        "            order=order,\n",
        "            seasonal_order=(0, 0, 0, 0),  # no seasonality for stock returns\n",
        "            exog=X_train,\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        results = model.fit(disp=False)\n",
        "\n",
        "        if results.aic < best_aic:\n",
        "            best_aic = results.aic\n",
        "            best_order = order\n",
        "            best_model = results\n",
        "    except Exception as e:\n",
        "        continue\n",
        "\n",
        "\n",
        "print(f\"Best SARIMAX order: {best_order} with AIC: {best_aic}\")\n",
        "print(best_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPM41mnK8Bh0"
      },
      "outputs": [],
      "source": [
        "\n",
        "forecast = best_model.get_forecast(steps=len(y_test), exog=X_test)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "\n",
        "\n",
        "rmse_ret = np.sqrt(mean_squared_error(y_test, forecast_mean))\n",
        "mae_ret = mean_absolute_error(y_test, forecast_mean)\n",
        "\n",
        "print(\"Metrics on Returns\")\n",
        "print(f\"RMSE: {rmse_ret:.6f}, MAE: {mae_ret:.6f}\")\n",
        "\n",
        "\n",
        "jnj_prices = jnj_sarima[\"Johnson_Close\"].reset_index(drop=True)\n",
        "\n",
        "actual_prices = jnj_prices[train_size:]\n",
        "\n",
        "last_train_price = jnj_prices[train_size - 1]\n",
        "forecast_prices = last_train_price * np.exp(forecast_mean.cumsum())\n",
        "\n",
        "rmse_price = np.sqrt(mean_squared_error(actual_prices, forecast_prices))\n",
        "mae_price = mean_absolute_error(actual_prices, forecast_prices)\n",
        "mape_price = mean_absolute_percentage_error(actual_prices, forecast_prices)\n",
        "\n",
        "print(\"Metrics on Prices\")\n",
        "print(f\"RMSE: {rmse_price:.2f}, MAE: {mae_price:.2f}, MAPE: {mape_price:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz_C9KRM2RiU"
      },
      "source": [
        "### Deep Learning Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmQmmNnjWgbw"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP9p7MiO-u8L"
      },
      "source": [
        "##### Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_2hZJux-vrU"
      },
      "outputs": [],
      "source": [
        "data = apple_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfz5RigM3r3"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])  #predict next 30\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "#reshape for LSTM\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "#build model\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # directly predict 30 steps\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "#train\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#forecast\n",
        "last_seq = scaled_data[-60:]  # last 60 days\n",
        "last_seq = last_seq.reshape((1, 60, 1))\n",
        "pred = model.predict(last_seq)\n",
        "pred = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Next 30-day forecast:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDj8FLGaOxEy"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()  # these are already in real price units\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={pred[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My7h_0EVx5qa"
      },
      "outputs": [],
      "source": [
        "print(\"Hello!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHWkm3baFosF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(range(len(y_true)), y_true, label=\"Actual Price\", color=\"black\")\n",
        "plt.plot(range(len(pred)), pred, label=\"LSTM Forecast (Univariate)\", color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.title(\"LSTM Forecast vs Actual (AAPL Closing Price)\")\n",
        "plt.xlabel(\"Days Ahead (Test Horizon)\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TWICyvOJFYz"
      },
      "outputs": [],
      "source": [
        "#RMSE\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "#MAE\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "#MAPE\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-E5Ukzh9tAl"
      },
      "outputs": [],
      "source": [
        "#close and exog\n",
        "\n",
        "apple_lstm = pd.concat([apple_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "apple_lstm.columns = [\"Apple_Close\", \"SP500_Close\"]\n",
        "apple_lstm = apple_lstm.dropna()\n",
        "\n",
        "apple_lstm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OttVGPi995J7"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(apple_lstm)\n",
        "\n",
        "def create_sequences_multivariate(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        #input includes both features\n",
        "        X.append(data[i-past_steps:i, :])\n",
        "        #target is only the stock Close (column 0)\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences_multivariate(scaled_data, 60, 30)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # predict next 30 days\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#last 60 days of features (stock + sp500)\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 2))\n",
        "\n",
        "y_pred = model.predict(last_seq)\n",
        "y_pred = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred.reshape(-1,1), np.zeros((30,1))], axis=1)\n",
        ")[:,0]  # keep only stock column\n",
        "\n",
        "# actual values for comparison\n",
        "y_true = apple_lstm['Apple_Close'].values[-30:]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={y_pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDJWxUX3lp3M"
      },
      "outputs": [],
      "source": [
        "#RMSE\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "#MAE\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "#MAPE\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2nByv3UGCcA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(range(len(y_true)), y_true, label=\"Actual Price\", color=\"black\")\n",
        "plt.plot(range(len(y_pred)), y_pred, label=\"LSTM Forecast (Multivariate)\", color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.title(\"LSTM Forecast vs Actual (AAPL Closing Price with SP500 Exogenous)\")\n",
        "plt.xlabel(\"Days Ahead (Test Horizon)\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Z74PdwW-BX"
      },
      "source": [
        "##### Goldman Sachs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOL2hv3vXQfd"
      },
      "outputs": [],
      "source": [
        "data = goldman_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP_5qgFLsNBc"
      },
      "source": [
        "###### Just the close price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2GYkGxbhiOy"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])  # predict next 30\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "#reshape for LSTM\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "#build model\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # directly predict 30 steps\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "#train\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#forecast\n",
        "last_seq = scaled_data[-60:]  # last 60 days\n",
        "last_seq = last_seq.reshape((1, 60, 1))\n",
        "pred = model.predict(last_seq)\n",
        "pred = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Next 30-day forecast:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6tYfef3jEaB"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()  # these are already in real price units\n",
        "\n",
        "#compare\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "\n",
        "#RMSE\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "#MAE\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "#MAPE\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hg-J60isTWk"
      },
      "source": [
        "###### Exog and Close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fpB_CX0sdQ9"
      },
      "outputs": [],
      "source": [
        "goldman_lstm = pd.concat([goldman_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "goldman_lstm.columns = [\"Goldman_Close\", \"SP500_Close\"]\n",
        "goldman_lstm = goldman_lstm.dropna()\n",
        "\n",
        "goldman_lstm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXwXkai0uSoT"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(goldman_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvuGsK0DueJo"
      },
      "outputs": [],
      "source": [
        "def create_sequences_multivariate(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        #input includes both features\n",
        "        X.append(data[i-past_steps:i, :])\n",
        "        #target is only the stock Close (column 0)\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences_multivariate(scaled_data, 60, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqCAmJYQuoE3"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # predict next 30 days\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXFc7J0Nv684"
      },
      "outputs": [],
      "source": [
        "#last 60 days of features (stock + sp500)\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 2))\n",
        "\n",
        "y_pred = model.predict(last_seq)\n",
        "y_pred = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred.reshape(-1,1), np.zeros((30,1))], axis=1)\n",
        ")[:,0]  # keep only stock column\n",
        "\n",
        "#actual values for comparison\n",
        "y_true = goldman_lstm['Goldman_Close'].values[-30:]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={y_pred[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nilWuwiBaqf3"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "rmse = (mse)**(1/2)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs9a7naEXAQI"
      },
      "source": [
        "##### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8yA9liiXPT2"
      },
      "outputs": [],
      "source": [
        "data = google_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AFlxJCf1jfwl"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])  # predict next 30\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "#reshape for LSTM\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "#build model\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # directly predict 30 steps\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "#train\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#forecast\n",
        "last_seq = scaled_data[-60:]  # last 60 days\n",
        "last_seq = last_seq.reshape((1, 60, 1))\n",
        "pred = model.predict(last_seq)\n",
        "pred = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Next 30-day forecast:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e6NhFGU3jjdi"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()  # these are already in real price units\n",
        "\n",
        "#compare\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D_i63f4p_PUr"
      },
      "outputs": [],
      "source": [
        "#close and exog\n",
        "\n",
        "google_lstm = pd.concat([google_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "google_lstm.columns = [\"Google_Close\", \"SP500_Close\"]\n",
        "google_lstm = google_lstm.dropna()\n",
        "\n",
        "google_lstm.head()\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(google_lstm)\n",
        "\n",
        "def create_sequences_multivariate(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        #input includes both features\n",
        "        X.append(data[i-past_steps:i, :])\n",
        "        # target is only the stock Close (column 0)\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences_multivariate(scaled_data, 60, 30)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)  # predict next 30 days\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#last 60 days of features (stock + sp500)\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 2))\n",
        "\n",
        "y_pred = model.predict(last_seq)\n",
        "y_pred = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred.reshape(-1,1), np.zeros((30,1))], axis=1)\n",
        ")[:,0]  # keep only stock column\n",
        "\n",
        "#actual values for comparison\n",
        "y_true = google_lstm['Google_Close'].values[-30:]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={y_pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "rmse = (mse)**(1/2)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bAOAnHYXCwZ"
      },
      "source": [
        "##### Citi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kG0-KQ-QXP1l"
      },
      "outputs": [],
      "source": [
        "data = citi_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xE-v7O3xlf8T"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])  # predict next 30\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "\n",
        "last_seq = scaled_data[-60:]  # last 60 days\n",
        "last_seq = last_seq.reshape((1, 60, 1))\n",
        "pred = model.predict(last_seq)\n",
        "pred = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Next 30-day forecast:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IoRaipsqmZKY"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()  # these are already in real price units\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SK0WVEIYBMyi"
      },
      "outputs": [],
      "source": [
        "#close and exog variable\n",
        "\n",
        "citi_lstm = pd.concat([citi_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "citi_lstm.columns = [\"Citi_Close\", \"SP500_Close\"]\n",
        "citi_lstm = citi_lstm.dropna()\n",
        "\n",
        "citi_lstm.head()\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(citi_lstm)\n",
        "\n",
        "def create_sequences_multivariate(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "\n",
        "        X.append(data[i-past_steps:i, :])\n",
        "\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences_multivariate(scaled_data, 60, 30)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 2))\n",
        "\n",
        "y_pred = model.predict(last_seq)\n",
        "y_pred = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred.reshape(-1,1), np.zeros((30,1))], axis=1)\n",
        ")[:,0]\n",
        "\n",
        "\n",
        "y_true = citi_lstm['Citi_Close'].values[-30:]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={y_pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "rmse = (mse)**(1/2)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR_go_yTXJot"
      },
      "source": [
        "##### Johnson and Johnson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FKZo4Li5XNKE"
      },
      "outputs": [],
      "source": [
        "data = johnson_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2or6zKCFm876"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 1))\n",
        "pred = model.predict(last_seq)\n",
        "pred = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(\"Next 30-day forecast:\", pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lZKBeTSpreKd"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_true, pred)\n",
        "rmse = (mse)**(1/2)\n",
        "mae = mean_absolute_error(y_true, pred)\n",
        "mape = np.mean(np.abs((y_true - pred) / y_true)) * 100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KtJNULrxF8eW"
      },
      "outputs": [],
      "source": [
        "#close and exog variable\n",
        "\n",
        "johnson_lstm = pd.concat([johnson_df[\"Close\"], sp_500[\"Close\"]], axis=1)\n",
        "johnson_lstm.columns = [\"Johnson_Close\", \"SP500_Close\"]\n",
        "johnson_lstm = johnson_lstm.dropna()\n",
        "\n",
        "johnson_lstm.head()\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(johnson_lstm)\n",
        "\n",
        "def create_sequences_multivariate(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "\n",
        "        X.append(data[i-past_steps:i, :])\n",
        "\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences_multivariate(scaled_data, 60, 30)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dropout(0.2),\n",
        "    Dense(30)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.1)\n",
        "\n",
        "\n",
        "last_seq = scaled_data[-60:]\n",
        "last_seq = last_seq.reshape((1, 60, 2))\n",
        "\n",
        "y_pred = model.predict(last_seq)\n",
        "y_pred = scaler.inverse_transform(\n",
        "    np.concatenate([y_pred.reshape(-1,1), np.zeros((30,1))], axis=1)\n",
        ")[:,0]\n",
        "\n",
        "\n",
        "y_true = johnson_lstm['Johnson_Close'].values[-30:]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Day {i+1}: Pred={y_pred[i]:.2f}, Actual={y_true[i]:.2f}\")\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "rmse = (mse)**(1/2)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdNMR-MONunL"
      },
      "source": [
        "#### Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hPHKJfWR2_L"
      },
      "source": [
        "##### Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7KxUOHVuSHHd"
      },
      "outputs": [],
      "source": [
        "data = apple_df[['Close']].values\n",
        "\n",
        "#scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "#creating the sequence\n",
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "#class to use torch\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_size = int(len(X)*0.9)\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "val_dataset = StockDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zliUySkSSVyh"
      },
      "outputs": [],
      "source": [
        "#transformer model\n",
        "class TransformerForecast(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.1, out_len=30):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=128,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, out_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x)                # [batch, seq_len, d_model]\n",
        "        x = self.transformer_encoder(x)     # [batch, seq_len, d_model]\n",
        "        x = x[:, -1, :]                     # use last time step\n",
        "        out = self.fc_out(x)                # [batch, out_len]\n",
        "        return out\n",
        "\n",
        "#training set up\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TransformerForecast().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    #validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            val_loss += loss.item()*xb.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WAkT2VzWSobt"
      },
      "outputs": [],
      "source": [
        "#forecast the next 30 days\n",
        "model.eval()\n",
        "last_seq = torch.tensor(scaled_data[-60:], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(last_seq).cpu().numpy()\n",
        "\n",
        "pred_prices = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "print(\"Next 30-day forecast:\", pred_prices)\n",
        "\n",
        "#evaluation\n",
        "y_true = data[-30:].flatten()\n",
        "mse = mean_squared_error(y_true, pred_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, pred_prices)\n",
        "mape = np.mean(np.abs((y_true - pred_prices)/y_true))*100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uZY5lXvaT6z2"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()  # these are already in real price units\n",
        "\n",
        "#compare\n",
        "for i in range(10):\n",
        "    print(f\"Day {i+1}: Pred={pred_prices[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EaW6foJTGRXs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(range(len(y_true)), y_true, label=\"Actual Price\", color=\"black\")\n",
        "plt.plot(range(len(pred_prices)), pred_prices, label=\"Transformer Forecast\", color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.title(\"Transformer Forecast vs Actual (AAPL Closing Price)\")\n",
        "plt.xlabel(\"Days Ahead (Test Horizon)\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJYTNxKqaEqr"
      },
      "source": [
        "##### Citi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L8YL3G_gaEqs"
      },
      "outputs": [],
      "source": [
        "data = citi_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_size = int(len(X)*0.9)\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "val_dataset = StockDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MlU8eKVxaEqs"
      },
      "outputs": [],
      "source": [
        "class TransformerForecast(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.1, out_len=30):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=128,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, out_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]\n",
        "        out = self.fc_out(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TransformerForecast().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            val_loss += loss.item()*xb.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pIi24BfeaEqs"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "last_seq = torch.tensor(scaled_data[-60:], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(last_seq).cpu().numpy()\n",
        "\n",
        "pred_prices = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "print(\"Next 30-day forecast:\", pred_prices)\n",
        "\n",
        "y_true = data[-30:].flatten()\n",
        "mse = mean_squared_error(y_true, pred_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, pred_prices)\n",
        "mape = np.mean(np.abs((y_true - pred_prices)/y_true))*100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7mk71UW7aEqs"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Day {i+1}: Pred={pred_prices[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oH0tSodbUOf"
      },
      "source": [
        "##### Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KM1tS-r4bUOf"
      },
      "outputs": [],
      "source": [
        "data = google_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_size = int(len(X)*0.9)\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "val_dataset = StockDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ngLzDVfRbUOg"
      },
      "outputs": [],
      "source": [
        "class TransformerForecast(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.1, out_len=30):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=128,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, out_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]\n",
        "        out = self.fc_out(x)\n",
        "        return out\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TransformerForecast().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            val_loss += loss.item()*xb.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5NbXdwX3bUOg"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "last_seq = torch.tensor(scaled_data[-60:], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(last_seq).cpu().numpy()\n",
        "\n",
        "pred_prices = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "print(\"Next 30-day forecast:\", pred_prices)\n",
        "\n",
        "y_true = data[-30:].flatten()\n",
        "mse = mean_squared_error(y_true, pred_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, pred_prices)\n",
        "mape = np.mean(np.abs((y_true - pred_prices)/y_true))*100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K0cAPa4dbUOg"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()\n",
        "for i in range(10):\n",
        "    print(f\"Day {i+1}: Pred={pred_prices[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ApIa9U6bbwA"
      },
      "source": [
        "##### Goldman Sachs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oF3nUa2BbbwA"
      },
      "outputs": [],
      "source": [
        "data = goldman_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_size = int(len(X)*0.9)\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "val_dataset = StockDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3X1MSILcbbwB"
      },
      "outputs": [],
      "source": [
        "class TransformerForecast(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.1, out_len=30):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=128,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, out_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]\n",
        "        out = self.fc_out(x)\n",
        "        return out\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TransformerForecast().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            val_loss += loss.item()*xb.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W2OvVC2xbbwB"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "last_seq = torch.tensor(scaled_data[-60:], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(last_seq).cpu().numpy()\n",
        "\n",
        "pred_prices = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "print(\"Next 30-day forecast:\", pred_prices)\n",
        "\n",
        "\n",
        "y_true = data[-30:].flatten()\n",
        "mse = mean_squared_error(y_true, pred_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, pred_prices)\n",
        "mape = np.mean(np.abs((y_true - pred_prices)/y_true))*100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "usvEd9kPbbwC"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Day {i+1}: Pred={pred_prices[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dql_KUA6bfto"
      },
      "source": [
        "##### Johnson and Johnson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yUSAiCWAbftp"
      },
      "outputs": [],
      "source": [
        "data = johnson_df[['Close']].values\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "def create_sequences(data, past_steps=60, future_steps=30):\n",
        "    X, y = [], []\n",
        "    for i in range(past_steps, len(data) - future_steps):\n",
        "        X.append(data[i-past_steps:i, 0])\n",
        "        y.append(data[i:i+future_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(scaled_data, 60, 30)\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_size = int(len(X)*0.9)\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "train_dataset = StockDataset(X_train, y_train)\n",
        "val_dataset = StockDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0wqgGb_qbftp"
      },
      "outputs": [],
      "source": [
        "class TransformerForecast(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=3, dropout=0.1, out_len=30):\n",
        "        super().__init__()\n",
        "        self.input_fc = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=128,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, out_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_fc(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[:, -1, :]\n",
        "        out = self.fc_out(x)\n",
        "        return out\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = TransformerForecast().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*xb.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            val_loss += loss.item()*xb.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YwWMKU1qbftp"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "last_seq = torch.tensor(scaled_data[-60:], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    pred = model(last_seq).cpu().numpy()\n",
        "\n",
        "pred_prices = scaler.inverse_transform(pred.reshape(-1, 1)).flatten()\n",
        "print(\"Next 30-day forecast:\", pred_prices)\n",
        "\n",
        "y_true = data[-30:].flatten()\n",
        "mse = mean_squared_error(y_true, pred_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, pred_prices)\n",
        "mape = np.mean(np.abs((y_true - pred_prices)/y_true))*100\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KgprjVn2bftp"
      },
      "outputs": [],
      "source": [
        "y_true = data[-30:].flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"Day {i+1}: Pred={pred_prices[i]:.2f}, Actual={y_true[i]:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}